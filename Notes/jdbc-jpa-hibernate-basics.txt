"All below notes are according to Udemy tutorial : Master Hibernate and JPA with Spring Boot in 100 Steps.
Course : Section 3 onwards
Corresponding Github Code Repo : Learn-Spring-SpringBoot/Learn-jdbc-jpa/Learn-jdbc-jpa/"

before springjdbc, even a single query line will be huge because of
1) get connection
2) prepare statement
3) execute it
4) iterate through the result
5) add try catch everywhere

with spring jdbc, we dont need to do any of this, all done by spring boot. we only need to execute the query and get back the result as the bean.

H2 -> In memory database

if we add a data.sql file in main/resources, springboot will use that file to initialize the h2 (because if you kill the server, database gets deleted and then everytime you need to add tables and stuff so this file will automatically do the job on server boot up)

@Repository -> marks that class as repository.
A repository is a mechanism for encapsulating storage, retrieval, and search behavior on the database

JdbcTemplate -> to execute the query, it automatically creates a connection with the database

JdbcTemplate.query -> we can pass a beanpropertyrowmapper which will automatically map the table to the bean we will provide.
if using beanpropertyrowmapper, need to have an empty contr present in the bean

if your defined class name or field names are different from the table then you can define your own RowMapper.
and map the table row columns with the corresponding class fields.

implementing CommandLineRunner in SpringBootApplication -> basically will execute the code, as soon as application context is ready, in CommandLineRunner (run method).

H2AutoConfiguration requires console.enabled plus WebServlet class present
DataSourceAutoConfiguration requires DataSource class
JdbcTemplateAutoConfiguration requires DataSource class and a primary bean

JPA standardizes ORM (object relational mapping)
Hibernate is the implementation of JPA (there are other implementations of JPA as well)

for JPA, we add Repository and Transaction because we can have multiple transactions and we want either to fail all or pass all.
Typically, transaction is managed at business service level than respository level.
If we are making changes to the db, we need to add @Transaction. (any method or sub called methods or UT)

Entity Manager -> manages the entities
all operations that we do are stored inside the PersistentContext for which Entity Manager is the interface.

So Hibernate actually creates the schema for us from the entity that we define so we dont need to create table everytime in data.sql

Hibernate creates a sequence (sql) and uses that seq to assign id automatically if @GeneratedValue is added.

findall (select * from table) method is not defined in JPA so we use JPQL namedquery.
JPQL uses entities instead of table names.

deleting data is transacational.

Entity Manager : persits vs merge -> https://stackoverflow.com/questions/1069992/jpa-entitymanager-why-use-persist-over-merge/

Entity Manager ->
perist - will track the entity (the entity fields will be updated but not sent to db) but actual update to db is sent only after flush() or automatically commit on method end. PersistentContext is the one handling all these entities.

flush - EntityManager.persist() makes an entity persistent whereas EntityManager.flush() actually runs the query on your database. So, when you call EntityManager.flush(), queries for inserting/updating/deleting associated entities are executed in the database. Any constraint failures (column width, data types, foreign key) will be known at this time. The concrete behaviour depends on whether flush-mode is AUTO or COMMIT. AUTO will force the changes to that entity to be flushed before the next SELECT execution(for eg). If it's set to COMMIT the persitence of the data to the underlying database will be delayed when the transaction is commited.

detach(Entity) - detach the entity so that it is not persisted. Anymore changes to entity will not be reflected in database until merge is called.

clear - detach all the entities within the method.

refresh(Entity) - reverts the entity values to the values that is in the db. So, any value changes made to entity after flush or commit will be lost and last updated value from db is fetched and set to the entity.

JPQL -
queries written on entities, also makes the complex queries easier on entities and relationships

@CreationTimestamp -> when row was created
@UpdateTimestamp -> when row was last updated

@NamedQuery -> no need to code it again, once define above entity and use it anywhere
For multiple named queries, use @NamedQueries

Native Queries -> direct sql queries in jpa (use tables instead of entities)
When using native queries, PersistentContext is not involved here so if using entites we need to refresh to get latest values from db

foreign key -> primary key in different table
student entity has passport id -> student table is owning the relationship

for OnetoOne -> details are Eager Fetched meaning if student data is retrieved then passport data is also retrieved with it because Student OnetoOne Passport.

To avoid this we can define in passport field in student entity, the fetchtype=lazy
With this, now when we do em.find it will only fetch student details.
And, if we try to do student.getpassport(), it will throw error because there wont be anymore transaction. Session ended on find student.
We can avoid this session ending by adding @Transactional to that method. It will prevent session from ending method exit, then can call student.getpassport() and it will again run the query to fetch passport details.

mappedBy ->
Student table can have passportid column and passport table can have studentid column but that will make it redundant.
So, we make one the owner of the relationship.
We add mappedBy in the @OnetoOne to the not-owning entity in the relationship.
Here, we make the Student the owner, so we add mappedBy="passport" in Passport entity.
This way we can get the student from the passport entity but no need to maintain student id column.
Called bidirectional navigation.

Hibernate waits until last step to push the entity to the db
Because if some error occurs in the transaction then we need to roll back the db changes. So, if we wait till last step, we can avoid this rollback.
And, even if we flush mid transaction, then also everything will be roll backed if some error occurs in the transaction.
This is because the whole thing is a transaction so its either 1 or 0.


@manytoone @onetomany ->
Course can have x reviews but review can be associated with only 1 Course
So Review table will have a course id (course table cannot have review id because one course can have multiple review ids and that will lead to row duplication)
Review entity will be the owning one relationship.
@OneToMany = current entity should be one and is different than owning the relationship.

If we persist before setting up the relationship, then first insert into review is made with blank course id and then an update review is sent to update the course id.

Fetch Type defaults for both hibernate and JPA latest ->
OneToMany: LAZY
ManyToOne: EAGER
ManyToMany: LAZY
OneToOne: EAGER

**ToOne is always EAGER

@ManyToMany ->
Create a join table that maps student id to course id or vice versa (because adding only in one table will make the relationship data become redundant)
If add ManyToMany on both entities, then in db there will be 2 tables course_student and student_course
So, we need to make one the owning table to avoid duplication of tables in db.
Also since, we will be using a join table so making any one the owning is fine. (owning by adding mappedBy to the other)

@JoinTable -> customize the join table created by manytomany, annontation added on owning side

Inheritance Relationship -> 4 methods

M1=Single Table Inheritance - Suppose employee has 2 sub class called fulltime and parttime, so we can use @Inheritance and use InheritanceType.SINGLE(default type) to save both employee types data in one table instead of creating 2 different tables and then joining them. It created one more column(DTYPE, can be customized with @DiscriminatorColumn) that differentiates whether the row is for fulltime or parttime. This is good for performance since there is only one table to look for data and fetch. But, data integrity is hampered since now hourlywage and salary needs to be made nullable (as one is null for other type). This can lead to data invalidity because now someone can put hourlywage as null for parttime employee which should not allowed (wage is important cannot be null).

M2=Table per class - Individual tables are created for Concrete classes (Employee is abstract so no table for employee but FullTime and PartTime are concrete so one table each is created for them and data is stored in different tables). Even though 2 tables will be created but that will be internal so no code changes are needed. We just need to insert for Employee. When we are retrieving data for all Employee, then internally from both tables data is retrieved and then union is done. Performance is ok (since union is not an issue and data is fetched from individual table) and data integrity is maintained. But, the issue is there is repitition of columns. The common columns are repeated in both tables and there might be a lot of columns that are common and those will be repeated.

M3=Joined - Employe has own table (common to other both tables columns only), FullTime has own table(own data column with id from Employee(fk)) and PartTime has own table(own data column with id from Employee(fk)). To retrieve data, 3 table joins were made so performance is low. But, data integrity is best since all have different tables and no data replication.

M4=Mapped Super Class - (Dont use @Inheritance) Use @MappedSuperClass. When a class is @MappedSuperClass, it cannot be an @Entity. So, no table for Employee itself. We cannot use "select e from Employee e" since Employee itself is not an Entity. So, to retrieve data, we need to retrieve all data individually from FullTime table and PartTime table.

M1 performance best at the cost of data integrity
M2 repeating columns so NO (3NF doesnt allow this)
M3 data integrity best at the cost of performance
M4 repeating columns so NO (3NF doesnt allow this)

JPQL using Entites and Relationships ->

JOIN = Select c,s from Course c join c.students s
LEFT JOIN = select c,s from Course c left join c.students s
CROSS JOIN = select c,s from Course c, Student s

Join will return courses that have students
Left Join will return courses with students and also courses that dont have students
Cross join is cross prod so if course has 4 rows and student as 3 rows, it will map every course with every student and return total of 12 rows.

When doing join, jpl returns an array of array. The whole result is an array that will have 2 arrays one for course and one for student. So, result[0] will be course array and result[1] is student when doing c,s

Criteria API ->

Writing queries is hard (even jpql) so instead write an api that does the task for us. (more complex tho)

Steps:
1) Use Criteria Builder to create a Criteria Query returning the expected result object
2) Define roots for tables which are involved in the Query (which table you are getting the data from)
3) Define Predicates etc using Criteria Builder
4) Add Predicates etc to the Criteria Query
5) Build the TypedQuery using the entity manager and criteria query

Transaction Management(Section 12) ->

Atomicity - either transaction is completely successful or none of them (rolled back)
Consistency - any transaction should leave the system in consistent state. (suppose A is transferring money to B, no matter the transaction failed or succeeded, the total money(A+B) should be same (consistent))
Isolation - how much inside of the transaction is visible to outside transaction (suppose A is transferring money to B, in between if someone wants to read the amount A has, then should it show the updated value?)
Durability - once transaction is successful, even if the system crashes (no matter what the end state), the data should be persisted (the result should be permanent).

Isolation related issues:
Transactions running parallel

Dirty Read -
A=200, B=300, C=500

T1 - A 50$ to B
T2 - A 100$ to C

Suppose T1 is executing and it deducted A balance by 50. In between, the T2 also starts and it deducts 100 from A. Now, A has 50. Now, suppose step 2 of T1 is executing where 50 deducted from A is bein transferred to B and IT FAILS. So, this transaction needs to rolled back since one step failed so T1 is rolled back. When rolling back T1, A will reset to 200 (this was the value of A before T1) and B will reset to 300 (50 is not added to B).
Now, step of T2 executes and 100 is added to C making C=600.
The system is not in consisted state because A has 200 (OK), B has 300 (OK) but C has 600 (NOT OK).
This happened because C started to executes its transaction midway T1 was executing. It read the modified value of A before the T1 (that modified the value of A) finished the execution. This read by C is called DIRTY READ.

Non Repeatable Read -
Person table(id, name, age)

Order of execution:
T1 Step 1 - Select * from Person where id is 10
T2 Step 1 - Update Person set age=30 where id is 10
T1 Step 2 - Select * from Person where id is 10

When T1 S1 was reading id10 age it was different and when T1 S2 was reading the age it was different.
While reading same thing twice (2 different points of same transaction), getting 2 different values. This is called Non Repeatable Read.

Phantom Read -
Person table(id, name, age)

Order of execution:
T1 Step 1 - Select * from Person where age between 4 and 44
T2 Step 1 - Insert Person Ravi(x,y,age=23)
T1 Step 2 - Select * from Person where age between 4 and 44

Here when T1 S2 executes, it will have one row extra than when it was in T1 S1.
While reading the same table twice (2 different points of same transaction), getting different number of rows. This is called Phantom Read. (phantom row is getting added(can be deleted also))

Isolation levels:

Read Uncommitted - allow all transactions to read whatever they want with or without commit.
issue= Dirty Read, Non Repeatable Read, Phantom Read

Read Uncommitted - allow other transaction to read data(cell values like age in Person table, or money value in A,B,C eg) that are only committed by using transaction.
updating other values of cell can happen and insertion of new rows as well so NRR and PR both can be done.
issue= No Dirty Read, Non Repeatable Read, Phantom Read

Repeatable Read - lock the whole row until the commit is done by the transaction. (the whole row that is being used by the transaction is locked even though only one cell value is being used)
eg from Non Repeatable Read, the T2 S1 wont be able to happen because the whole row will be locked. So no NRR.
The table is still accessible so Insert can happen and so Phanton Read is possible.
issue= No Dirty Read, No Non Repeatable Read, Phantom Read

Serializable - here table lock is placed on the table for a specific constraint that is being used in the Transation.
In Phantom Read eg, the table lock will be placed for all rows where age is between 4 and 44. (So Ravi cant be inserted at all)
if there is no constraint (selec t * from Person) then whole table will be locked so no data insertion can happen in between. (Solved all issue)
issue= No Dirty Read, No Non Repeatable Read, No Phantom Read

Which to use?
Performance wise Serializable is worst because if 1000 transactions (all select * from table) are happening in parallel then only 1 will be executed at a time because of table lock down till one transation finished. So, very poor performance.
Typically, Read Committed is mostly used (good performance and somewhat data consistency).

@Transactional -> Springframework vs javax.persitence
this annontation is available in 2 packages.
Javax.persitence (JPA) one is recommended when we dealing with 1 singular database.
Springframework one is recommended when we are dealing with multiple databases and multiple message queues as well.

With Springframework we can also use @Transactional(isolation = IsoltionType.X) where X will be above 4 isolation levels.

We can also define an application level isolation level in application.properties with "spring.jpa.properties.hibernate.connection.isolation=x" x is the value for transation isolation level.
